import os
import logging
import json
from datetime import datetime
from queue import Queue
from typing import List, Tuple, Dict, Any, Callable, Generator
from flask import Response
from modules.prcs_flow import create_nmap_output_template, merge_nmap_output_template, ProcessingError
from modules.prcs_shp import process_zip
from modules.prcs_geojson import process_geojson
from modules.prcs_gpx import process_gpx
from modules.prcs_kml import process_kml
from modules.prcs_topojson import process_topojson
from modules.prcs_wkt import process_wkt
from modules.prcs_nspd_locality import process_nspd_locality
from modules.prcs_nspd_border import process_nspd_border
from modules.prcs_upload import (
    download_index_json,
    upload_index_json,
    ensure_folder,
    get_current_day_folder_path,
    BASE_FOLDER_PATH
)

logger = logging.getLogger(__name__)

ALLOWED_EXTENSIONS = {'zip', 'geojson', 'gpx', 'kml', 'kmz', 'topojson', 'wkt'}

FILE_PROCESSORS: Dict[str, Tuple[Callable[[str], Dict[str, Any]], str]] = {
    '.zip': (process_zip, 'Shapefile'),
    '.geojson': (process_geojson, 'GeoJSON'),
    '.gpx': (process_gpx, 'GPX'),
    '.kml': (process_kml, 'KML/KMZ'),
    '.kmz': (process_kml, 'KML/KMZ'),
    '.topojson': (process_topojson, 'TopoJSON'),
    '.wkt': (process_wkt, 'WKT'),
}


class QueueHandler(logging.Handler):

    def __init__(self, log_queue: Queue):
        super().__init__()
        self.log_queue = log_queue

    def emit(self, record: logging.LogRecord) -> None:
        log_entry = {
            'time': datetime.now().strftime('%H:%M:%S'),
            'level': record.levelname.lower(),
            'message': self.format(record)
        }
        self.log_queue.put(log_entry)


def allowed_file(filename: str) -> bool:
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def _get_file_extension(filename: str) -> str:
    return '.' + filename.rsplit('.', 1)[1].lower() if '.' in filename else ''


def _setup_logging(log_queue: Queue) -> QueueHandler:
    queue_handler = QueueHandler(log_queue)
    queue_handler.setLevel(logging.INFO)
    queue_handler.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(queue_handler)
    return queue_handler


def _ensure_storage_folders() -> None:
    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –±–∞–∑–æ–≤–æ–π –ø–∞–ø–∫–∏ –≤ –ë–ª–æ–∫–Ω–æ—Ç–µ –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∞")
    ensure_folder(BASE_FOLDER_PATH)
    logger.info("‚úì –ë–∞–∑–æ–≤–∞—è –ø–∞–ø–∫–∞ –µ—Å—Ç—å")

    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–ø–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã")
    ensure_folder(get_current_day_folder_path())
    logger.info("‚úì –ü–∞–ø–∫–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã –µ—Å—Ç—å")


def _load_current_index() -> Dict[str, Any]:
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞ index.json")
    current_index = download_index_json()

    if current_index is None:
        current_index = create_nmap_output_template()
        logger.info("–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª index.json")
    else:
        logger.info("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω")

    return current_index


def _process_single_file(temp_path: str, filename: str) -> Dict[str, Any]:
    extension = _get_file_extension(filename)

    if extension not in FILE_PROCESSORS:
        raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {extension}")

    processor, format_name = FILE_PROCESSORS[extension]
    logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è {format_name}")

    return processor(temp_path)


def process_upload_async(log_queue: Queue, session_id: str, temp_files: List[Tuple[str, str]]) -> None:
    queue_handler = _setup_logging(log_queue)

    try:
        if not temp_files:
            logger.error("–ù–µ –≤—ã–±—Ä–∞–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return

        try:
            _ensure_storage_folders()
        except ProcessingError as e:
            logger.error(f"–î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–π OAuth-—Ç–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –≤ config.py")
            return

        try:
            current_index = _load_current_index()
        except ProcessingError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª index.json: {e.message}")
            return

        new_data = create_nmap_output_template()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(temp_files)} —Ñ–∞–π–ª(–æ–≤)")

        processed_count = 0
        skipped_count = 0

        for temp_path, filename in temp_files:
            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞: {filename}")

            try:
                result = _process_single_file(temp_path, filename)
                new_data = merge_nmap_output_template(new_data, result)
                logger.info(f"‚úì {filename} —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ index.json")
                processed_count += 1

            except ProcessingError as e:
                logger.error(f"‚úó {filename}: {e.message}")
                skipped_count += 1
            except ValueError as e:
                logger.error(f"‚úó {filename}: {str(e)}")
                skipped_count += 1
            except Exception as e:
                logger.error(f"‚úó {filename}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ - {str(e)}")
                skipped_count += 1
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)

        if processed_count > 0:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–ª–æ–∫–Ω–æ—Ç –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∞")
            try:
                final_index = merge_nmap_output_template(current_index, new_data)
                upload_index_json(final_index)
                logger.info("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω")
            except ProcessingError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e.message}")

        logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {processed_count} —É—Å–ø–µ—à–Ω–æ, {skipped_count} –ø—Ä–æ–ø—É—â–µ–Ω–æ")

    finally:
        logger.removeHandler(queue_handler)
        log_queue.put(None)


def create_sse_stream(session_id: str, log_queues: Dict[str, Queue]) -> Response:
    def generate() -> Generator[str, None, None]:
        if session_id not in log_queues:
            return

        log_queue = log_queues[session_id]

        while True:
            log_entry = log_queue.get()

            if log_entry is None:
                if session_id in log_queues:
                    del log_queues[session_id]
                break

            yield f"data: {json.dumps(log_entry)}\n\n"

    return Response(generate(), mimetype='text/event-stream')

def process_nspd_async(log_queue: Queue, session_id: str, registry_number: str) -> None:
    queue_handler = _setup_logging(log_queue)

    try:
        if not registry_number:
            logger.error("–ù–µ —É–∫–∞–∑–∞–Ω —Ä–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä")
            return

        try:
            _ensure_storage_folders()
        except ProcessingError as e:
            logger.error(f"–î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–π OAuth-—Ç–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –≤ config.py")
            return

        try:
            current_index = _load_current_index()
        except ProcessingError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª index.json: {e.message}")
            return

        new_data = create_nmap_output_template()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–µ—Å—Ç—Ä–æ–≤–æ–≥–æ –Ω–æ–º–µ—Ä–∞: {registry_number}")

        try:
            result = process_nspd_locality(registry_number)
            new_data = merge_nmap_output_template(new_data, result)
            logger.info(f"‚úì –î–∞–Ω–Ω—ã–µ –¥–ª—è {registry_number} –ø–æ–ª—É—á–µ–Ω—ã –∏ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
            
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–ª–æ–∫–Ω–æ—Ç –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∞")
            try:
                final_index = merge_nmap_output_template(current_index, new_data)
                upload_index_json(final_index)
                logger.info("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω")
            except ProcessingError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e.message}")

        except ProcessingError as e:
            logger.error(f"‚úó –û—à–∏–±–∫–∞: {e.message}")
        except Exception as e:
            logger.error(f"‚úó –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

    finally:
        logger.removeHandler(queue_handler)
        log_queue.put(None)


def process_nspd_border_async(log_queue: Queue, session_id: str, registry_number: str) -> None:
    queue_handler = _setup_logging(log_queue)

    try:
        if not registry_number:
            logger.error("–ù–µ —É–∫–∞–∑–∞–Ω —Ä–µ–µ—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä")
            return

        try:
            _ensure_storage_folders()
        except ProcessingError as e:
            logger.error(f"–î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–π OAuth-—Ç–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å.–î–∏—Å–∫–∞ –≤ config.py")
            return

        try:
            current_index = _load_current_index()
        except ProcessingError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª index.json: {e.message}")
            return

        new_data = create_nmap_output_template()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: {registry_number}")

        try:
            result = process_nspd_border(registry_number)
            new_data = merge_nmap_output_template(new_data, result)
            logger.info(f"‚úì –î–∞–Ω–Ω—ã–µ –ú–û –¥–ª—è {registry_number} –ø–æ–ª—É—á–µ–Ω—ã –∏ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
            
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–ª–æ–∫–Ω–æ—Ç –∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∞")
            try:
                final_index = merge_nmap_output_template(current_index, new_data)
                upload_index_json(final_index)
                logger.info("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω")
            except ProcessingError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e.message}")

        except ProcessingError as e:
            logger.error(f"‚úó –û—à–∏–±–∫–∞: {e.message}")
        except Exception as e:
            logger.error(f"‚úó –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

    finally:
        logger.removeHandler(queue_handler)
        log_queue.put(None)
